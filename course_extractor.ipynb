{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools we need to get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Tools that we need to run this program \"\"\"\n",
    "from time import sleep\n",
    "import csv\n",
    "import sys\n",
    "import copy\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should not listen to what pylint has to say here\n",
    "# pylint: disable=too-many-locals, too-many-branches, too-many-statements, unspecified-encoding, consider-using-with\n",
    "\"\"\" Extracts (and make a csv file in your directory) information on\n",
    "        every single section of each course offered in the selecter semester at UIUC\n",
    "\n",
    "    Args:\n",
    "        year (string): academic year\n",
    "        semester (string): choose from spring, summer, fall, and winter\n",
    "\"\"\"\n",
    "semester = 'fall'\n",
    "year = '2022'\n",
    "# open/create a csv file\n",
    "file = open(f'{semester}{year}_courses.csv', 'w')\n",
    "writer = csv.writer(file)\n",
    "csv_header = ['Year','Semester','SubjectName','SubjectId','CourseNumber','CourseName'\n",
    "                ,'Description','CreditHours','CRN','SectionNumber','SectionType','StartTime',\n",
    "                'EndTime','DaysOfWeek','RoomNumber','BuildingName','MainInstructor']\n",
    "# write the csv header to the csv file\n",
    "writer.writerow(csv_header)\n",
    "# connect to the UIUC Course Explorer API\n",
    "url = f'https://courses.illinois.edu/cisapp/explorer/schedule/{year}/{semester}.xml'\n",
    "xml_data = requests.get(url).content\n",
    "soup = BeautifulSoup(xml_data, 'xml')\n",
    "subjects = soup.find_all('subject')\n",
    "# traverse the subject list\n",
    "for subject in subjects:\n",
    "    row = [year, semester, subject.string, subject['id']]\n",
    "    course_data = ''\n",
    "    done = False\n",
    "    # We need to catch an exception wait for a bit when we send a bunch of HTTP\n",
    "    # requests to the API so that the connection error stops the whole program\n",
    "    while done is False:\n",
    "        try:\n",
    "            course_data = requests.get(subject['href']).content\n",
    "            done = True\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            sleep(5)\n",
    "    soup1 = BeautifulSoup(course_data, 'xml')\n",
    "    courses = soup1.find_all('course')\n",
    "    # traverse a course list\n",
    "    for course in courses:\n",
    "        sub_row = copy.deepcopy(row)\n",
    "        sub_row.append(course['id'])\n",
    "        sub_row.append(course.string)\n",
    "        section_data = ''\n",
    "        done = False\n",
    "        # We need to catch an exception wait for a bit when we send a bunch of HTTP\n",
    "        # requests to the API so that the connection error stops the whole program\n",
    "        while done is False:\n",
    "            try:\n",
    "                section_data = requests.get(course['href']).content\n",
    "                done = True\n",
    "            except requests.exceptions.ConnectionError:\n",
    "                sleep(5)\n",
    "        sections_data = BeautifulSoup(section_data, 'xml')\n",
    "        sub_sub_row = copy.deepcopy(sub_row)\n",
    "        if sections_data.find('description') is not None:\n",
    "            sub_sub_row.append(sections_data.find('description').string)\n",
    "        else:\n",
    "            sub_sub_row.append('')\n",
    "        if sections_data.find('creditHours') is not None:\n",
    "            sub_sub_row.append(sections_data.find('creditHours').string.replace('.', ''))\n",
    "        else:\n",
    "            sub_sub_row.append('')\n",
    "        sections = sections_data.find_all('section')\n",
    "        for section in sections:\n",
    "            sub_sub_sub_row = copy.deepcopy(sub_sub_row)\n",
    "            sub_sub_sub_row.append(section['id'])\n",
    "            sub_sub_sub_row.append(section.string)\n",
    "            # Some courses have an invalid link which causes the whole\n",
    "            # program to stop and we'd never let this happen\n",
    "            if 'http://cis.local' in section['href']:\n",
    "                continue\n",
    "            specific_data = ''\n",
    "            done = False\n",
    "            # We need to catch an exception wait for a bit when we send a bunch of HTTP\n",
    "            # requests to the API so that the connection error stops the whole program\n",
    "            while done is False:\n",
    "                try:\n",
    "                    specific_data = requests.get(section['href']).content\n",
    "                    done = True\n",
    "                except requests.exceptions.ConnectionError:\n",
    "                    sleep(5)\n",
    "            soup2 = BeautifulSoup(specific_data, 'xml')\n",
    "            complete_row = copy.deepcopy(sub_sub_sub_row)\n",
    "            about_section = soup2.find('meeting')\n",
    "            complete_row.append(about_section.find('type').string)\n",
    "            complete_row.append(about_section.find('start').string)\n",
    "            if about_section.find('end') is not None:\n",
    "                complete_row.append(about_section.find('end').string)\n",
    "            else:\n",
    "                complete_row.append('')\n",
    "            if about_section.find('daysOfTheWeek') is not None:\n",
    "                complete_row.append(about_section.find('daysOfTheWeek').string.replace(' ', ''))\n",
    "            else:\n",
    "                complete_row.append('')\n",
    "            if about_section.find('roomNumber') is not None:\n",
    "                complete_row.append(about_section.find('roomNumber').string)\n",
    "            else:\n",
    "                complete_row.append('')\n",
    "            if about_section.find('buildingName') is not None:\n",
    "                complete_row.append(about_section.find('buildingName').string)\n",
    "            else:\n",
    "                complete_row.append('')\n",
    "            instructors = about_section.find('instructors')\n",
    "            instructor = ''\n",
    "            if len(instructors.find_all('instructor')) != 0:\n",
    "                instructor = instructors.find_all('instructor')[0].string\n",
    "            complete_row.append(instructor)\n",
    "            # write the complete information on a section of a course to the csv file\n",
    "            writer.writerow(complete_row)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
